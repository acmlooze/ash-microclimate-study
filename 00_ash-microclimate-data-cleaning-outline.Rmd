---
title: "ash-microclimate-data-cleaning"
author: "Deidre Jaeger"
date: "10/12/2018"
output: html_document
---

Data cleaning steps
1) import the tree data csv file
  - check that the classes are correct for numbers and factors
  - import dates as.date
2) import the sensor datafiles
 - check that the classes are correct for numbers and factors
 - import dates as.date
 
3) check if sensors were turned off during morning of day 3 (Sep 20)
 
 4) combine all data into 1 spreadsheet
 - column names ()
 - each row is temperature measurement at a given minute
 
```{r-load-libraries}

```
 
 
 
```{r-import-data}

# import the data from each sensor

# open the first file of the treatment-tree 100e, from the "before" removal
treatment_100e_before <- read.csv("data/SN 20439121 2018-09-20 00_06_33 -0600.csv", # define the file name
                          skip = 1, # skip reading the first row
                          header = TRUE, # define the second row as the header
                          col.names = c("date_time", "tempF", "sensor_name", "ash_removal", "blank1",  "blank2")) # rename the columns


treatment_100e_before$blank1 <- NULL # Remove the blank columns
treatment_100e_before$blank2 <- NULL # Remove the blank columns

treatment_100e_before$sensor_name <- rep("treatment_100e") # fill column with the sensor name
treatment_100e_before$ash_removal <- rep("before_removal") # fill the column with the ash removal status

# check the first 6 rows to see if the dataframe looks as we expect
head(treatment_100e_before)

# check the structure of how it is loaded
str(treatment_100e_before) # we will eventually want date to be formated as date, but for now having number for temp and character for sensor name look good


# open the second file of the treatment-tree 100e, from the "after" removal
# open the first file of the treatment-tree 100e, from the "before" removal
treatment_100e_after <- read.csv("data/SN 20439121 2018-09-26 10_27_52 -0600.csv", # define the file name
                          skip = 1, # skip reading the first row
                          header = TRUE, # define the second row as the header
                          col.names = c("date_time", "tempF", "sensor_name", "ash_removal", "blank1",  "blank2")) # rename the columns
sensor_100e_after$blank1 <- NULL # Remove the blank columns
sensor_100e_after$blank2 <- NULL # Remove the blank columns
sensor_100e_after$sensor_name <- rep("treatment_100e") # fill column with the sensor name
sensor_100e_after$ash_removal <- rep("after_removal") # fill the column with the ash removal status

# check the first 6 rows to see if the dataframe looks as we expect
head(sensor_100e_after)

# check the structure of how it is loaded
str(sensor_100e_after) # we will eventually want date to be formated as date, but for now having number for te

# could create a loop to do this for all the files in the temp data folder
# dataframe names:
treatment_100e_before
treatment_100e_after 
treatment_101w_before
treatment_101w_after
control_ash_before # will want to omit the times when the treatment sensors were off on Sept 20
control_ash_after # will want to omit the times when the treatment sensors were off on Sept 20
control_sun_before # will want to omit the times when the treatment sensors were off on Sept 20
control_sun_after # will want to omit the times when the treatment sensors were off on Sept 20



```
 
```{r-example-for-loop-data-loading}

clean_up_raw_accel_csv <- function(files, output_path) {
  # This function will loop through a folder of raw Gulf Data Concepts Accelerometer Data csv files and produce a cleaned up and simplified csv that has columns: Seconds Elapsed, Ax, Ay, and Az acceleration axis, and the starting file timestamp
  ## Inputs are: 1) a list of files within a folder and 2) a path for the folder to which the new outputs will be stored
  ## Outputs are: the new csv files named with the site name and the original file number
  
  for (f in (1:(length(files)))) {
    site_meta <- read.csv(files[f], 
                             header= TRUE, # allow a header row
                             skip = 1, # skip the first row
                             col.names = c("Item", "Date", "Time", "blank1", "blank2"),
                             nrows = 1) # stop reading data after 1 row
    site_meta$blank1 <- NULL # Remove the null column
    site_meta$blank2 <- NULL # Remove the null column
    
    site_acc <- read.csv(files[f], # specify the file
                            skip = 7, # skip the first 7 rows
                            header = TRUE,
                            col.names = c("sec_elapse", "Ax", "Ay", "Az", "blank1"))
    site_acc$blank1 <- NULL # Remove the null column
    
    # reformat date to class date
    site_meta <- site_meta %>% 
      mutate(Date = as.Date(Date, format = "%Y-%m-%d")) %>% # reformat date
      mutate(day_time = paste(Date, Time)) %>% 
      mutate(day_time = as.POSIXct(day_time, format = "%Y-%m-%d %H:%M:%S"))
    
    # pull out the date
    site_date <- site_meta$Date
    # pull out the starting time
    site_start_time <- site_meta$day_time
    
    # parse out variable names
    csv_file_number <- gsub(".*-|\\.csv$", "", files[f])
    csv_site_name <- gsub("(.*Fall2017/)", "", files[f]) # keep everything after Fall 2017 in path name
    csv_site_name <- gsub("(/GCDC.*)", "", csv_site_name) 
    
    # Add Date and starting time column to site_acc, 
    site_acc <- site_acc %>% 
      mutate(Time = site_start_time) %>% 
      # write a new csv file as an output into a new MAIN folder
      write.csv(file = paste0(output_path, csv_site_name,"-", csv_file_number)) # using pipes, write a new csv file saved at the defined filepath
      print(paste0(csv_site_name,"-", csv_file_number, " created"))
  }
}

```
 
```{r-use-function-data-loading}
# Run function for each of the sites:

##### MAIN1
main1_files <- list.files("/Volumes/BIG_DATA1/Accelerometer/Fall2017/MAIN1/GCDC/",
                         full.names = TRUE)
main1_path = "/Users/deidrejaeger/Documents/Career/CU-Boulder/Research/BoulderPhenology/Accelerometers/Fall2017_study/outputs/main1/"
clean_up_raw_accel_csv(main1_files, main1_path)
```

 
 
```{r-bind-into-1-csv}

# aggregate the before and after dataframes into 1 dataframe

# for example:
sensor_data <- rbind(sensor_100e_before, sensor_100e_after)


```
 
```{r-format-date-time}

as.date()

```
 
 
 